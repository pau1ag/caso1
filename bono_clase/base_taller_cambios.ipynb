{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import patsy\n",
    "import itertools\n",
    "from IPython.display import display, HTML\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import KFold\n",
    "from ipywidgets import interact\n",
    "import ipywidgets as widgets\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from ipywidgets import interact\n",
    "import ipywidgets as widgets \n",
    "\n",
    "from scipy import stats\n",
    "from sklearn.impute import KNNImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_credit = pd.read_csv(\"Credit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_credit.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valores_unicos = df_credit['Region'].unique()\n",
    "valores_unicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_credit['Own'] = df_credit['Own'].map({'Yes': 1, 'No': 0})\n",
    "df_credit['Student'] = df_credit['Student'].map({'Yes': 1, 'No': 0})\n",
    "df_credit['Married'] = df_credit['Married'].map({'Yes': 1, 'No': 0})\n",
    "df_credit['Region'] = df_credit['Region'].map({'South': 1, 'West': 2, 'South':3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_credit.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_credit.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_credit.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se toma Balance como variable de respuesta (Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exog = df_credit[['Income', 'Limit', 'Rating', 'Cards', 'Age', 'Education', 'Own', 'Student', 'Married', 'Region']]\n",
    "\n",
    "# Verificar si hay valores nulos en tus datos de variables independientes\n",
    "valores_nulos = exog.isnull().any()\n",
    "print(\"Valores nulos en variables independientes:\")\n",
    "print(valores_nulos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_credit.replace(np.nan, None, inplace=True)\n",
    "df_credit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_credit= df_credit.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valores_faltantes = exog.isnull().sum()\n",
    "\n",
    "print(\"Número de valores faltantes en variables independientes:\")\n",
    "print(valores_faltantes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''imputador = KNNImputer(n_neighbors=5)\n",
    "\n",
    "# Llenar valores faltantes utilizando KNN\n",
    "exog_lleno = imputador.fit_transform(exog)\n",
    "\n",
    "# Convertir la matriz de NumPy resultante de vuelta a un DataFrame de pandas\n",
    "exog_lleno = pd.DataFrame(exog_lleno, columns=exog.columns)\n",
    "\n",
    "print(\"DataFrame con valores faltantes llenados por KNN:\")\n",
    "print(exog_lleno)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valores_faltantes2 = exog_lleno.isnull().sum()\n",
    "\n",
    "print(\"Número de valores faltantes en variables independientes:\")\n",
    "print(valores_faltantes2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_indep = [\"Income\", \"Limit\", \"Rating\", \"Cards\", \"Age\", \"Education\", \"Own\", \"Student\", \"Married\", \"Region\"]\n",
    "X = df_credit[variables_indep]\n",
    "\n",
    "y = df_credit[[\"Balance\"]]\n",
    "X = sm.add_constant(X)  # Add constant column for intercept\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = sm.OLS(y, X).fit()\n",
    "\n",
    "# Obtener el resumen del modelo\n",
    "print(modelo.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = eps = np.random.normal(0 ,1 , 400)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_independientes = ['Limit', 'Rating', 'Cards', 'Age', 'Education', 'Own', 'Student', 'Married', 'Region', 'Balance']\n",
    "x = df_credit[variables_independientes]\n",
    "\n",
    "np.random.seed(0)\n",
    "error = np.random.normal(loc=0, scale=0.1, size=len(df_credit))\n",
    "df_credit['variable_dependiente'] = (2 * X['Limit'] + 3 * X['Rating'] +\n",
    "                                     4 * X['Cards'] + 5 * X['Age'] +\n",
    "                                     6 * X['Education']+\n",
    "                                     7 * X['Own']+\n",
    "                                     8 * X['Student']+\n",
    "                                     9 * X['Married']+\n",
    "                                     10 * X['Region']+\n",
    "                                     11 * X['Balance'] + error)\n",
    "\n",
    "\n",
    "# Generar una variable dependiente y agregar error\n",
    "np.random.seed(0)\n",
    "error = np.random.normal(loc=0, scale=0.1, size=len(df_credit))\n",
    "df_credit['variable_dependiente'] = (2 * x['var1'] + 3 * x['var2'] +\n",
    "                                     4 * x['var3'] + 5 * x['var4'] +\n",
    "                                     6 * x['var5'] + error)\n",
    "\n",
    "# Graficar los datos en un scatter plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "for variable in variables_independientes:\n",
    "    plt.scatter(df_credit[variable], df_credit['variable_dependiente'], label=variable)\n",
    "plt.xlabel('Variables independientes')\n",
    "plt.ylabel('Variable dependiente')\n",
    "plt.title('Scatter plot de variables independientes vs variable dependiente')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_np = 1 + 2*x + 3*(x**2) + 2.5*(x**3) + eps\n",
    "sns.scatterplot(x=X, y=y_np);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.OLS(y, x).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_np =  + 3*(x**2) + 2.5*(x**3)\n",
    "sns.scatterplot(x=x, y=y_np);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de dataset para regresión\n",
    "X = df_credit[[\"Limit\", \"Rating\", \"Cards\", \"Age\", \"Education\", \"Own\", \"Student\", \"Married\", \"Region\", \"Balance\"]]  # Your independent variable(s)\n",
    "y = df_credit[\"Income\"]  # Your dependent variable\n",
    "X = sm.add_constant(X)  # Add constant column for intercept\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_models(k, X, y):\n",
    "    \"\"\"\n",
    "    Fit all possible models that contain exactly k predictors.\n",
    "    \"\"\"\n",
    "    # List all available predictors\n",
    "    X_combos = itertools.combinations(list(X.columns), k)\n",
    "    \n",
    "    # Fit all models accumulating Residual Sum of Squares (RSS)\n",
    "    models = []\n",
    "    for X_label in X_combos:\n",
    "        # Parse patsy formula\n",
    "        X_smf = ' + '.join(X_label)\n",
    "        f     = '{} ~ {}'.format(y.columns[0], X_smf)\n",
    "        # Fit model\n",
    "        model = smf.ols(formula=f, data=pd.concat([X, y], axis=1)).fit()\n",
    "        # Return results\n",
    "        models += [(f, model)]\n",
    "    return models\n",
    "\n",
    "\n",
    "def min_rss(statsmodels):\n",
    "    \"\"\"Return model with lowest Residual Sum of Squares (RSS)\"\"\"\n",
    "    return sorted(statsmodels, key=lambda tup: tup[1].ssr)[0]\n",
    "\n",
    "\n",
    "def max_adjr2(statsmodels):\n",
    "    \"\"\"Return model with max R-squared\"\"\"\n",
    "    return sorted(statsmodels, reverse=True, key=lambda tup: tup[1].rsquared_adj)[0]\n",
    "\n",
    "def min_bic(statsmodels):\n",
    "    \"\"\"Return model with min Bayes' Information Criteria\"\"\"\n",
    "    return sorted(statsmodels, reverse=False, key=lambda tup: tup[1].bic)[0]\n",
    "\n",
    "def min_aic(statsmodels):\n",
    "    \"\"\"Return model with min Akaike's Information Criteria\"\"\"\n",
    "    return sorted(statsmodels, reverse=False, key=lambda tup: tup[1].aic)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame({'X': x,\n",
    "                  'X2': x**2,\n",
    "                  'X3': x**3,\n",
    "                  'X4': x**4,\n",
    "                  'X5': x**5,\n",
    "                  'X6': x**6,\n",
    "                  'X7': x**7,\n",
    "                  'X8': x**8,\n",
    "                  'X9': x**9,\n",
    "                  'X10': x**10})\n",
    "y = pd.DataFrame({'y': y_np})\n",
    "\n",
    "# get all model results\n",
    "model_subsets = []\n",
    "for k in range(len(X.columns)):\n",
    "    k=k+1\n",
    "    subset = get_models(k, X, y)\n",
    "    model_subsets += [subset]\n",
    "    print('Progess: k = {}, done'.format(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictor count\n",
    "k = np.arange(1, len(X.columns)+1)\n",
    "\n",
    "# adjr2\n",
    "# ------------------------------------------------\n",
    "display(HTML('<h4>Adjusted R^2</h4>'))\n",
    "\n",
    "# Plot best r-squared score for each subset\n",
    "adjr2 = [max_adjr2(m)[1].rsquared_adj for m in model_subsets]\n",
    "\n",
    "sns.lineplot(x=k, y=adjr2)\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('$R^2$')\n",
    "plt.show()\n",
    "\n",
    "# Select best subset\n",
    "coefs_r2 = [(max_adjr2(m)[1].rsquared_adj, max_adjr2(m)[1].params) for m in model_subsets]\n",
    "print('Model selected: \\n{}'.format(max(coefs_r2)[1]))\n",
    "\n",
    "\n",
    "# Bayes' Information Criteria (BIC)\n",
    "# ------------------------------------------------\n",
    "display(HTML('<h4>Bayes\\' Information Criteria</h4>'))\n",
    "\n",
    "# Get best BIC\n",
    "bic = [min_bic(m)[1].bic for m in model_subsets]\n",
    "\n",
    "sns.lineplot(x=k, y=bic)\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('BIC')\n",
    "plt.show()\n",
    "\n",
    "# Select best subset\n",
    "coefs_bic = [(min_bic(m)[1].bic, min_bic(m)[1].params) for m in model_subsets]\n",
    "print('Model selected: \\n{}'.format(min(coefs_bic)[1]))\n",
    "\n",
    "\n",
    "# Akaike's Information Criteria (AIC/ C_p)\n",
    "# ------------------------------------------------\n",
    "display(HTML('<h4>Akaike\\'s Information Criteria</h4>'))\n",
    "\n",
    "# Get best AIC\n",
    "aic = [min_aic(m)[1].aic for m in model_subsets]\n",
    "\n",
    "sns.lineplot(x=k, y=aic)\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('AIC')\n",
    "plt.show()\n",
    "\n",
    "# Select best subset\n",
    "coefs_aic = [(min_aic(m)[1].aic, min_aic(m)[1].params) for m in model_subsets]\n",
    "print('Model selected: \\n{}'.format(min(coefs_aic)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_stepwise(X, y, scorer='ssr', results=[(0, [])]):\n",
    "    \"\"\"Perform forward stepwise variable selection as described in\n",
    "    An Introductions to Statistical Learning (p.207)\n",
    "    Returns pandas dataframe object  with results for each step\"\"\"\n",
    "    # List predictors that havent's been used so far\n",
    "    p_all    = list(X.columns)\n",
    "    p_used   = results[-1][1]\n",
    "    p_unused = [p for p in p_all if p not in p_used]\n",
    "    \n",
    "    # Job done, exit recursion\n",
    "    if not p_unused:\n",
    "        scores = [r[0] for r in results]\n",
    "        preds  = [r[1] for r in results]\n",
    "        return pd.DataFrame({scorer: scores, 'predictors': preds}).drop(0)\n",
    "    \n",
    "    # Get score for each possible additional predictor\n",
    "    r = []\n",
    "    for p in p_unused:\n",
    "        f     = '{} ~ {}'.format(y.columns[0], '+'.join([p]+p_used))\n",
    "        # Fit model\n",
    "        model = smf.ols(formula=f, data=pd.concat([X, y], axis=1)).fit()\n",
    "        r    += [(model, [p]+p_used)]\n",
    "    \n",
    "    # Choose predictor which yields best score\n",
    "    if scorer == 'ssr':\n",
    "        best_model = sorted(r, key=lambda tup: tup[0].ssr)[0]\n",
    "        best_score = (best_model[0].ssr, best_model[1])\n",
    "    elif scorer == 'rsquared_adj':\n",
    "        best_model = sorted(r, key=lambda tup: tup[0].rsquared_adj)[-1]\n",
    "        best_score = (best_model[0].rsquared_adj, best_model[1])        \n",
    "    elif scorer == 'bic':\n",
    "        best_model = sorted(r, key=lambda tup: tup[0].bic)[0]\n",
    "        best_score = (best_model[0].bic, best_model[1]) \n",
    "    elif scorer == 'aic':\n",
    "        best_model = sorted(r, key=lambda tup: tup[0].aic)[0]\n",
    "        best_score = (best_model[0].aic, best_model[1]) \n",
    "                        \n",
    "    new_results = results + [best_score]\n",
    "    # Recursive call to self\n",
    "    return forward_stepwise(X, y, scorer, new_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_stepwise(X, y, scorer='ssr', results=[]):\n",
    "    \"\"\"Perform backward stepwise variable selection as described in\n",
    "    An Introductions to Statistical Learning (p.209)\n",
    "    Returns pandas dataframe object  with results for each step\"\"\"\n",
    "    # List predictors that havent's been used so far\n",
    "    p_all = list(X.columns)\n",
    "\n",
    "    # Check if we're starting out here\n",
    "    if not results:\n",
    "        # Fit model with all features\n",
    "        f     = '{} ~ {}'.format(y.columns[0], '+'.join(p_all))\n",
    "        model = smf.ols(formula=f, data=pd.concat([X, y], axis=1)).fit()\n",
    "        # Begin backward stepwise recursion\n",
    "        if scorer == 'ssr':\n",
    "            return backward_stepwise(X, y, scorer, [(model.ssr, p_all)])\n",
    "        if scorer == 'rsquared_adj':\n",
    "            return backward_stepwise(X, y, scorer, [(model.rsquared_adj, p_all)])\n",
    "        if scorer == 'bic':\n",
    "            return backward_stepwise(X, y, scorer, [(model.bic, p_all)])\n",
    "        if scorer == 'aic':\n",
    "            return backward_stepwise(X, y, scorer, [(model.aic, p_all)])\n",
    "    else:\n",
    "        p_used = results[-1][1]\n",
    "    \n",
    "    # Job done, exit recursion\n",
    "    if len(p_used) == 1:\n",
    "        scores = [r[0] for r in results]\n",
    "        preds  = [r[1] for r in results]\n",
    "        return pd.DataFrame({scorer: scores, 'predictors': preds})    \n",
    "    \n",
    "    # Get rss score for each possible removed predictor\n",
    "    r = []\n",
    "    for p in p_used:\n",
    "        p_test = [i for i in p_used if i != p]\n",
    "        f     = '{} ~ {}'.format(y.columns[0], '+'.join(p_test))\n",
    "        # Fit model\n",
    "        model = smf.ols(formula=f, data=pd.concat([X, y], axis=1)).fit()\n",
    "        r     += [(model, p_test)]\n",
    "    \n",
    "    # Choose removal of predictor which yields best score\n",
    "    if scorer == 'ssr':\n",
    "        best_model = sorted(r, key=lambda tup: tup[0].ssr)[0]\n",
    "        best_score = (best_model[0].ssr, best_model[1])\n",
    "    elif scorer == 'rsquared_adj':\n",
    "        best_model = sorted(r, key=lambda tup: tup[0].rsquared_adj)[-1]\n",
    "        best_score = (best_model[0].rsquared_adj, best_model[1])        \n",
    "    elif scorer == 'bic':\n",
    "        best_model = sorted(r, key=lambda tup: tup[0].bic)[0]\n",
    "        best_score = (best_model[0].bic, best_model[1]) \n",
    "    elif scorer == 'aic':\n",
    "        best_model = sorted(r, key=lambda tup: tup[0].aic)[0]\n",
    "        best_score = (best_model[0].aic, best_model[1]) \n",
    "\n",
    "    new_results = results + [best_score]\n",
    "    # Recursive call to self\n",
    "    return backward_stepwise(X, y, scorer, new_results)\n",
    "\n",
    "\n",
    "def subset_analysis(df, scorer):\n",
    "    \"\"\"Renders results from forward_stepwise() and backward_stepwise()\"\"\"\n",
    "    df['predictors_str'] = df['predictors'].astype(str)\n",
    "    \n",
    "    ax = sns.lineplot(x='predictors_str', y=scorer, data=df, sort=False)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.show();\n",
    "    \n",
    "    if scorer == 'rsquared_adj':\n",
    "        display(df[df[scorer] ==  df[scorer].max()].drop('predictors_str', axis=1))\n",
    "    else:\n",
    "        display(df[df[scorer] ==  df[scorer].min()].drop('predictors_str', axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjr2\n",
    "# ------------------------------------------------\n",
    "display(HTML('<h4>Adjusted R^2</h4>'))\n",
    "scorer = 'rsquared_adj'\n",
    "subset_analysis(forward_stepwise(X, y, scorer=scorer), scorer)\n",
    "\n",
    "# Bayes' Information Criteria (BIC)\n",
    "# ------------------------------------------------\n",
    "display(HTML('<h4>Bayes\\' Information Criteria</h4>'))\n",
    "scorer = 'bic'\n",
    "subset_analysis(forward_stepwise(X, y, scorer=scorer), scorer)\n",
    "\n",
    "# Akaike's Information Criteria (AIC/ C_p)\n",
    "# ------------------------------------------------\n",
    "display(HTML('<h4>Akaike\\'s Information Criteria</h4>'))\n",
    "scorer = 'aic'\n",
    "subset_analysis(forward_stepwise(X, y, scorer=scorer), scorer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adjr2\n",
    "# ------------------------------------------------\n",
    "display(HTML('<h4>Adjusted R^2</h4>'))\n",
    "scorer = 'rsquared_adj'\n",
    "subset_analysis(backward_stepwise(X, y, scorer=scorer), scorer)\n",
    "\n",
    "# Bayes' Information Criteria (BIC)\n",
    "# ------------------------------------------------\n",
    "display(HTML('<h4>Bayes\\' Information Criteria</h4>'))\n",
    "scorer = 'bic'\n",
    "subset_analysis(backward_stepwise(X, y, scorer=scorer), scorer)\n",
    "\n",
    "# Akaike's Information Criteria (AIC/ C_p)\n",
    "# ------------------------------------------------\n",
    "display(HTML('<h4>Akaike\\'s Information Criteria</h4>'))\n",
    "scorer = 'aic'\n",
    "subset_analysis(backward_stepwise(X, y, scorer=scorer), scorer)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
